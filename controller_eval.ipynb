{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Will\n",
      "[nltk_data]     Blanton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "e:\\VS_Projects\\Q-A-5525\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from answer_extraction import NER_Extractor\n",
    "from controller import Controller\n",
    "from distraction_generation import DistractionFinder\n",
    "from qa_evaluation import QA_Evaluator\n",
    "from question_generation.question_gen_en import QuestionGenerator\n",
    "from sklearn.metrics import f1_score\n",
    "from translation import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_JSON = \"data/xquad.en.json\"\n",
    "SPANISH_JSON = \"data/xquad.es.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSLATION_FILE = \"data/qa_results_translation.json\"\n",
    "NO_TRANSLATION_FILE = \"data/qa_results_no_translation.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qa_data(json_file):\n",
    "    \n",
    "    articles = pd.read_json(json_file)\n",
    "\n",
    "    # turn the json into a list of dictionaries\n",
    "    articles = [a for a in articles[\"data\"]]\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_comparison(original: str, translated: str):\n",
    "    \"\"\"\n",
    "    Compare the generated questions with the dataset questions using BLEU score\n",
    "    \"\"\"\n",
    "\n",
    "    original_tokens = word_tokenize(original.lower())\n",
    "\n",
    "    translated_tokens = word_tokenize(translated.lower())\n",
    "\n",
    "    bleu_score = sentence_bleu([original_tokens], translated_tokens)\n",
    "\n",
    "    bleu_score = bleu_score if bleu_score >= .0001 else 0\n",
    "\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_f1(true_answer, predicted_answer):\n",
    "    # Tokenize the answers\n",
    "    true_tokens = true_answer.lower().split()\n",
    "    predicted_tokens = predicted_answer.lower().split()\n",
    "    \n",
    "    # Create sets for easier comparison\n",
    "    true_set = set(true_tokens)\n",
    "    predicted_set = set(predicted_tokens)\n",
    "    \n",
    "    # Create binary arrays\n",
    "    true_labels = [1 if token in true_set else 0 for token in true_tokens + predicted_tokens]\n",
    "    predicted_labels = [1 if token in predicted_set else 0 for token in true_tokens + predicted_tokens]\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_qa_pair(controller: Controller, \n",
    "                  english: dict, \n",
    "                  spanish: dict, \n",
    "                  display: bool = False,\n",
    "                  translate: bool = True):\n",
    "    \"\"\"\n",
    "    Iterate over the articles and paragraphs in the English and Spanish data to translate,\n",
    "    the Spansih data is translated to English and then generate questions and answers in English.\n",
    "    Evaluate \n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    evaluator = QA_Evaluator()\n",
    "\n",
    "    # iterate through the articles and paragraphs\n",
    "    for i, article in enumerate(english):\n",
    "        for j, paragraph in enumerate(article[\"paragraphs\"]):\n",
    "            if display and j >= 1:\n",
    "                break\n",
    "\n",
    "            # get the text to translate\n",
    "            spanish_context = spanish[i][\"paragraphs\"][j][\"context\"]\n",
    "\n",
    "            # get the correct translation\n",
    "            target_context = paragraph[\"context\"]\n",
    "\n",
    "\n",
    "            # skip if the context is too large\n",
    "            try:\n",
    "                if translate:\n",
    "                    translated_context, qa_pairs = controller.gen_qa_pairs(spanish_context)\n",
    "                else:\n",
    "                    translated_context, qa_pairs = controller.gen_qa_pairs(target_context,\n",
    "                                                                        translate=False)\n",
    "                \n",
    "\n",
    "                # bleu_score = bleu_comparison(target_context, translated_context)\n",
    "\n",
    "                if display:\n",
    "                    print(\"--------------------------------------------------\\n\")\n",
    "                    print(f\"Spanish Context: {spanish_context}\\n\")\n",
    "                    print(f\"English Context: {target_context}\\n\")\n",
    "                    print(f\"Translated Context: {translated_context}\\n\")\n",
    "                    #print(f\"BLEU Score: {bleu_score}\\n\")\n",
    "                    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "                # target_qa = []\n",
    "                # for qas in paragraph[\"qas\"]:\n",
    "                #     target_question = qas[\"question\"]\n",
    "                #     target_answer = qas[\"answers\"][0][\"text\"]\n",
    "                    \n",
    "                #     target_qa.append((target_question, target_answer))\n",
    "\n",
    "                for gen_q, extr_a, extr_dist in qa_pairs:\n",
    "\n",
    "                    gen_a, sim_score = evaluator.evaluate_qa_pair(translated_context, gen_q, extr_a)\n",
    "\n",
    "                    results.append({\n",
    "                        \"article_index\": i,\n",
    "                        # \"spanish_context\": spanish_context,\n",
    "                        # \"target_context\": target_context,\n",
    "                        \"translated_context\": translated_context,\n",
    "                        #\"bleu_score\": bleu_score,\n",
    "                        \"generated_question\": gen_q,\n",
    "                        \"extracted_answer\": extr_a,\n",
    "                        \"QA_answer\": gen_a,\n",
    "                        \"QA_similarity_score\": sim_score,\n",
    "                        \"QA_F1\": compute_f1(extr_a, gen_a),\n",
    "                        #\"distractions\": extr_dist\n",
    "                    })\n",
    "\n",
    "                    if display:\n",
    "                        print(\"--------------------------------------------------\\n\")\n",
    "                        print(f\"Generated-Q: {gen_q}\\n\")\n",
    "                        print(f\"Extracted-A: {extr_a}\\n\")\n",
    "                        #print(f\"Distractions: {extr_dist}\\n\")\n",
    "                        # print(f\"Target-QA: {target_qa}\\n\")\n",
    "                        print(\"--------------------------------------------------\\n\")\n",
    "            \n",
    "            except IndexError as e:\n",
    "                print(f\"An index error occurred: {str(e)}\")\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.set_index([\"article_index\", \n",
    "                          \"translated_context\",\n",
    "                          \"generated_question\"], inplace=True)\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_system(controller, english, spanish, save_path, translate=True):\n",
    "\n",
    "    if os.path.exists(save_path):\n",
    "        qa_results = pd.read_json(save_path, orient='index')\n",
    "        qa_results.index = pd.MultiIndex.from_tuples(qa_results.index.map(eval))\n",
    "        qa_results.index.names = [\"article_index\", \"translated_context\", \"generated_question\"]\n",
    "    else:\n",
    "        qa_results = score_qa_pair(controller, \n",
    "                                   english, \n",
    "                                   spanish, \n",
    "                                   display=False,\n",
    "                                   translate=translate)\n",
    "\n",
    "        # remove duplicates\n",
    "        qa_results = qa_results[~qa_results.index.duplicated(keep=False)]\n",
    "\n",
    "        # save results to json\n",
    "        qa_results.to_json(save_path, orient='index', indent=4)\n",
    "\n",
    "    return qa_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VS_Projects\\Q-A-5525\\venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "controller = Controller(\n",
    "    translator=Translator(device=device),\n",
    "    extractor=NER_Extractor(),\n",
    "    question_generator=QuestionGenerator(),\n",
    "    distraction_finder=DistractionFinder()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_qa = load_qa_data(ENGLISH_JSON)\n",
    "spanish_qa = load_qa_data(SPANISH_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 48)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(english_qa), len(spanish_qa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Language-Learning QA-Pair System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An index error occurred: index out of range in self\n",
      "An index error occurred: index out of range in self\n",
      "An index error occurred: index out of range in self\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>extracted_answer</th>\n",
       "      <th>QA_answer</th>\n",
       "      <th>QA_similarity_score</th>\n",
       "      <th>QA_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_index</th>\n",
       "      <th>translated_context</th>\n",
       "      <th>generated_question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">The Panthers, who in addition to leading the NFL interceptions with 24 and counting four players of the Pro Bowl, gave up only 308 points in defense and placed themselves in the sixth place of the league. Kawann Short, defensive tag of the Pro Bowl, led the team with 11 catches, 3 forced looseballs and 2 recoveries. In turn, the lineer Mario Addison, got 6 and a half catches. In the line of the Panthers, he also highlighted as defensive wing veteran Jared Allen –5 times player of the Pro Bowl and who was the leader, in active, of catches of the NFL with 136– along with the also defensive wing Kony Ealy, who carries 5 catches in only 9 games as holder. Behind them, Thomas Davis and Luke Kuechly, two of the three incumbent supporters who have also been selected to play the Pro Bowl. Davis made 5 and a half catches, 4 loose balls forced and 4 intercepts, while Kuechly led the team in passers (118), forced 2 single balls and he made 2 single balls from the Pro Bowl. Davis was made with 5 and a half side.</th>\n",
       "      <th>Who led the Panthers in passers?</th>\n",
       "      <td>Kuechly</td>\n",
       "      <td>Kuechly</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How many incumbent supporters have been selected to play the Pro Bowl?</th>\n",
       "      <td>three</td>\n",
       "      <td>three</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Broncos beat the Pittsburgh Steelers in the divisional round by 23 to 16 when they scored 11 points in the last three minutes of the match. Subsequently, in the AFC Championship, they beat the champion of the title of the Super Bowl XLIX, the New England Patriots by 20 to 18. When there were only 17 seconds left on the scoreboard, they managed to intercept a pass in an attempt to convert 2 points from the New England. Despite Manning’s problems with the interceptions last season, he did not disappoint in either of their two elimination games.</th>\n",
       "      <th>Who beat the Pittsburgh Steelers in the divisional round?</th>\n",
       "      <td>Broncos</td>\n",
       "      <td>The Broncos</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    extracted_answer  \\\n",
       "article_index translated_context                                 generated_question                                                    \n",
       "0             The Panthers, who in addition to leading the NF... Who led the Panthers in passers?                            Kuechly   \n",
       "                                                                 How many incumbent supporters have been selecte...            three   \n",
       "              The Broncos beat the Pittsburgh Steelers in the... Who beat the Pittsburgh Steelers in the divisio...          Broncos   \n",
       "\n",
       "                                                                                                                       QA_answer  \\\n",
       "article_index translated_context                                 generated_question                                                \n",
       "0             The Panthers, who in addition to leading the NF... Who led the Panthers in passers?                        Kuechly   \n",
       "                                                                 How many incumbent supporters have been selecte...        three   \n",
       "              The Broncos beat the Pittsburgh Steelers in the... Who beat the Pittsburgh Steelers in the divisio...  The Broncos   \n",
       "\n",
       "                                                                                                                     QA_similarity_score  \\\n",
       "article_index translated_context                                 generated_question                                                        \n",
       "0             The Panthers, who in addition to leading the NF... Who led the Panthers in passers?                                 1.0000   \n",
       "                                                                 How many incumbent supporters have been selecte...               1.0000   \n",
       "              The Broncos beat the Pittsburgh Steelers in the... Who beat the Pittsburgh Steelers in the divisio...               0.9511   \n",
       "\n",
       "                                                                                                                     QA_F1  \n",
       "article_index translated_context                                 generated_question                                         \n",
       "0             The Panthers, who in addition to leading the NF... Who led the Panthers in passers?                      1.0  \n",
       "                                                                 How many incumbent supporters have been selecte...    1.0  \n",
       "              The Broncos beat the Pittsburgh Steelers in the... Who beat the Pittsburgh Steelers in the divisio...    0.8  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_results = evaluate_system(controller, \n",
    "                             english_qa, \n",
    "                             spanish_qa, \n",
    "                             TRANSLATION_FILE, \n",
    "                             translate=True)\n",
    "\n",
    "qa_results.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QA_similarity_score</th>\n",
       "      <th>QA_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>764.000000</td>\n",
       "      <td>764.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.826955</td>\n",
       "      <td>0.722862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.259432</td>\n",
       "      <td>0.393134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.018658</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.712589</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QA_similarity_score       QA_F1\n",
       "count           764.000000  764.000000\n",
       "mean              0.826955    0.722862\n",
       "std               0.259432    0.393134\n",
       "min               0.018658    0.000000\n",
       "25%               0.712589    0.571429\n",
       "50%               1.000000    1.000000\n",
       "75%               1.000000    1.000000\n",
       "max               1.000000    1.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_results.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Without Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (661 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>extracted_answer</th>\n",
       "      <th>QA_answer</th>\n",
       "      <th>QA_similarity_score</th>\n",
       "      <th>QA_F1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>article_index</th>\n",
       "      <th>translated_context</th>\n",
       "      <th>generated_question</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">The Panthers defense gave up just 308 points, ranking sixth in the league, while also leading the NFL in interceptions with 24 and boasting four Pro Bowl selections. Pro Bowl defensive tackle Kawann Short led the team in sacks with 11, while also forcing three fumbles and recovering two. Fellow lineman Mario Addison added 6½ sacks. The Panthers line also featured veteran defensive end Jared Allen, a 5-time pro bowler who was the NFL's active career sack leader with 136, along with defensive end Kony Ealy, who had 5 sacks in just 9 starts. Behind them, two of the Panthers three starting linebackers were also selected to play in the Pro Bowl: Thomas Davis and Luke Kuechly. Davis compiled 5½ sacks, four forced fumbles, and four interceptions, while Kuechly led the team in tackles (118) forced two fumbles, and intercepted four passes of his own. Carolina's secondary featured Pro Bowl safety Kurt Coleman, who led the team with a career high seven interceptions, while also racking up 88 tackles and Pro Bowl cornerback Josh Norman, who developed into a shutdown corner during the season and had four interceptions, two of which were returned for touchdowns.</th>\n",
       "      <th>How many of the Panthers' three starting linebackers were selected to play in the Pro Bowl?</th>\n",
       "      <td>two</td>\n",
       "      <td>Two</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Who led the Panthers in sacks with 11?</th>\n",
       "      <td>Kawann Short</td>\n",
       "      <td>Kawann Short</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>The Broncos defeated the Pittsburgh Steelers in the divisional round, 23–16, by scoring 11 points in the final three minutes of the game. They then beat the defending Super Bowl XLIX champion New England Patriots in the AFC Championship Game, 20–18, by intercepting a pass on New England's 2-point conversion attempt with 17 seconds left on the clock. Despite Manning's problems with interceptions during the season, he didn't throw any in their two playoff games.</th>\n",
       "      <th>How many playoff games did the Broncos lose?</th>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                    extracted_answer  \\\n",
       "article_index translated_context                                 generated_question                                                    \n",
       "0             The Panthers defense gave up just 308 points, r... How many of the Panthers' three starting lineba...              two   \n",
       "                                                                 Who led the Panthers in sacks with 11?                 Kawann Short   \n",
       "              The Broncos defeated the Pittsburgh Steelers in... How many playoff games did the Broncos lose?                    two   \n",
       "\n",
       "                                                                                                                        QA_answer  \\\n",
       "article_index translated_context                                 generated_question                                                 \n",
       "0             The Panthers defense gave up just 308 points, r... How many of the Panthers' three starting lineba...           Two   \n",
       "                                                                 Who led the Panthers in sacks with 11?              Kawann Short   \n",
       "              The Broncos defeated the Pittsburgh Steelers in... How many playoff games did the Broncos lose?                 two   \n",
       "\n",
       "                                                                                                                     QA_similarity_score  \\\n",
       "article_index translated_context                                 generated_question                                                        \n",
       "0             The Panthers defense gave up just 308 points, r... How many of the Panthers' three starting lineba...                  1.0   \n",
       "                                                                 Who led the Panthers in sacks with 11?                              1.0   \n",
       "              The Broncos defeated the Pittsburgh Steelers in... How many playoff games did the Broncos lose?                        1.0   \n",
       "\n",
       "                                                                                                                     QA_F1  \n",
       "article_index translated_context                                 generated_question                                         \n",
       "0             The Panthers defense gave up just 308 points, r... How many of the Panthers' three starting lineba...    1.0  \n",
       "                                                                 Who led the Panthers in sacks with 11?                1.0  \n",
       "              The Broncos defeated the Pittsburgh Steelers in... How many playoff games did the Broncos lose?          1.0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_translation = evaluate_system(controller, \n",
    "                             english_qa, \n",
    "                             spanish_qa, \n",
    "                             NO_TRANSLATION_FILE, \n",
    "                             translate=False)\n",
    "\n",
    "wo_translation.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QA_similarity_score</th>\n",
       "      <th>QA_F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>801.000000</td>\n",
       "      <td>801.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.812440</td>\n",
       "      <td>0.705860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.270848</td>\n",
       "      <td>0.400450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.036753</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.682343</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       QA_similarity_score       QA_F1\n",
       "count           801.000000  801.000000\n",
       "mean              0.812440    0.705860\n",
       "std               0.270848    0.400450\n",
       "min               0.036753    0.000000\n",
       "25%               0.682343    0.533333\n",
       "50%               1.000000    0.941176\n",
       "75%               1.000000    1.000000\n",
       "max               1.000000    1.000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wo_translation.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
