{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Will\n",
      "[nltk_data]     Blanton\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "e:\\VS_Projects\\Q-A-5525\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from answer_extraction import NER_Extractor\n",
    "from controller import Controller\n",
    "from distraction_generation import DistractionFinder\n",
    "from qa_evaluation import QA_Evaluator\n",
    "from question_generation.question_gen_en import QuestionGenerator\n",
    "from translation import Translator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENGLISH_JSON = \"data/xquad.en.json\"\n",
    "SPANISH_JSON = \"data/xquad.es.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_qa_data(json_file):\n",
    "    \n",
    "    articles = pd.read_json(json_file)\n",
    "\n",
    "    # turn the json into a list of dictionaries\n",
    "    articles = [a for a in articles[\"data\"]]\n",
    "\n",
    "    return articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bleu_comparison(original: str, translated: str):\n",
    "    \"\"\"\n",
    "    Compare the generated questions with the dataset questions using BLEU score\n",
    "    \"\"\"\n",
    "\n",
    "    original_tokens = word_tokenize(original.lower())\n",
    "\n",
    "    translated_tokens = word_tokenize(translated.lower())\n",
    "\n",
    "    bleu_score = sentence_bleu([original_tokens], translated_tokens)\n",
    "\n",
    "    bleu_score = bleu_score if bleu_score >= .0001 else 0\n",
    "\n",
    "    return bleu_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_qa_pair(controller, english: dict, spanish: dict, display: bool = False):\n",
    "    \"\"\"\n",
    "    Iterate over the articles and paragraphs in the English and Spanish data to translate,\n",
    "    the Spansih data is translated to English and then generate questions and answers in English.\n",
    "    Evaluate \n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    evaluator = QA_Evaluator()\n",
    "\n",
    "    # iterate through the articles and paragraphs\n",
    "    for i, article in enumerate(english[0:1]):\n",
    "        for j, paragraph in enumerate(article[\"paragraphs\"]):\n",
    "            if display and j >= 1:\n",
    "                break\n",
    "\n",
    "            # get the text to translate\n",
    "            spanish_context = spanish[i][\"paragraphs\"][j][\"context\"]\n",
    "\n",
    "            translated_context, qa_pairs = controller.gen_qa_pairs(spanish_context)\n",
    "\n",
    "            # get the correct translation\n",
    "            target_context = paragraph[\"context\"]\n",
    "\n",
    "            bleu_score = bleu_comparison(target_context, translated_context)\n",
    "\n",
    "            if display:\n",
    "                print(\"--------------------------------------------------\\n\")\n",
    "                print(f\"Spanish Context: {spanish_context}\\n\")\n",
    "                print(f\"English Context: {target_context}\\n\")\n",
    "                print(f\"Translated Context: {translated_context}\\n\")\n",
    "                print(f\"BLEU Score: {bleu_score}\\n\")\n",
    "                print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "            target_qa = []\n",
    "            for qas in paragraph[\"qas\"]:\n",
    "                target_question = qas[\"question\"]\n",
    "                target_answer = qas[\"answers\"][0][\"text\"]\n",
    "                \n",
    "                target_qa.append((target_question, target_answer))\n",
    "\n",
    "            for gen_q, extr_a, extr_dist in qa_pairs:\n",
    "\n",
    "                gen_a = evaluator.answer_question(gen_q, target_context, answer)\n",
    "\n",
    "                results.append({\n",
    "                    \"article_index\": i,\n",
    "                    \"paragraph_index\": j,\n",
    "                    \"spanish_context\": spanish_context,\n",
    "                    \"target_context\": target_context,\n",
    "                    \"translated_context\": translated_context,\n",
    "                    \"bleu_score\": bleu_score,\n",
    "                    \"generated_question\": gen_q,\n",
    "                    \"extracted_answer\": extr_a,\n",
    "                    \"distractions\": extr_dist\n",
    "                })\n",
    "\n",
    "                if display:\n",
    "                    print(\"--------------------------------------------------\\n\")\n",
    "                    print(f\"Generated-Q: {gen_q}\\n\")\n",
    "                    print(f\"Extracted-A: {extr_a}\\n\")\n",
    "                    print(f\"Distractions: {extr_dist}\\n\")\n",
    "                    # print(f\"Target-QA: {target_qa}\\n\")\n",
    "                    print(\"--------------------------------------------------\\n\")\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\VS_Projects\\Q-A-5525\\venv\\Lib\\site-packages\\transformers\\models\\marian\\tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
      "  warnings.warn(\"Recommended: pip install sacremoses.\")\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n",
      "The `xla_device` argument has been deprecated in v4.4.0 of Transformers. It is ignored and you can safely remove it from your `config.json` file.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "controller = Controller(\n",
    "    Translator(device=device),\n",
    "    QuestionGenerator(),\n",
    "    NER_Extractor(),\n",
    "    DistractionFinder()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_qa = load_qa_data(ENGLISH_JSON)\n",
    "spanish_qa = load_qa_data(SPANISH_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Language-Learning QA-Pair System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_qa_pair(controller, english_qa, spanish_qa, display=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
